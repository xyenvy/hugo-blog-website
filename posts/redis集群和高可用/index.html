<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Redis集群和高可用 | Hopeful</title>
<meta name="keywords" content="Redis">
<meta name="description" content="Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题">
<meta name="author" content="yuan kun">
<link rel="canonical" href="http://gz0854.com/posts/redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://gz0854.com/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="http://gz0854.com/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="http://gz0854.com/img/Q.gif">
<link rel="apple-touch-icon" href="http://gz0854.com/img/Q.gif">
<link rel="mask-icon" href="http://gz0854.com/img/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<meta property="og:title" content="Redis集群和高可用" />
<meta property="og:description" content="Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://gz0854.com/posts/redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/" />
<meta property="og:image" content="http://oss.itshare.work/itshare-work-images/29.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-13T22:20:06+00:00" />
<meta property="article:modified_time" content="2022-12-13T22:20:06+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://oss.itshare.work/itshare-work-images/29.jpg" />
<meta name="twitter:title" content="Redis集群和高可用"/>
<meta name="twitter:description" content="Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "📚文章",
          "item": "http://gz0854.com/posts/"
        }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Redis集群和高可用",
      "item": "http://gz0854.com/posts/redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis集群和高可用",
  "name": "Redis集群和高可用",
  "description": "Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题",
  "keywords": [
    "Redis"
  ],
  "articleBody": "简介 Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题.\n主从复制实现 主从命令配置 当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则的话，由于延迟等问题，部署的主节点Redis服务应该要避免自动启动。\n参考案例: 导致主从服务器数据全部丢失\n1.假设节点A为主服务器，并且关闭了持久化。并且节点B和节点C从节点A复制数据 2.节点A崩溃，然后由自动拉起服务重启了节点A.由于节点A的持久化被关闭了，所以重启之后没有任何数据 3.节点B和节点C将从节点A复制数据，但是A的数据是空的，于是就把自身保存的数据副本删除。 在关闭主服务器上的持久化，并同时开启自动拉起进程的情况下，即便使用Sentinel来实现Redis的高可用性，也是非常危险的。因为主服务器可能拉起得非常快，以至于Sentinel在配置的心跳时间间隔内没有检测到主服务器已被重启，然后还是会执行上面的数据丢失的流程。无论何时，数据安全都是极其重要的，所以应该禁止主服务器关闭持久化的同时自动启动。\n启用主从同步 Redis Server 默认为 master节点，如果要配置为从节点,需要指定master服务器的IP,端口及连接密码在从节点执行 REPLICAOF MASTER_IP PORT 指令可以启用主从同步复制功能,早期版本使用 SLAVEOF指令\n127.0.0.1:6379\u003e REPLICAOF MASTER_IP PORT #新版推荐使用 127.0.0.1:6379\u003e SLAVEOF MasterIP Port #旧版使用，将被淘汰 127.0.0.1:6379\u003e CONFIG SET masterauth 在master实现 127.0.0.1:6379\u003e AUTH 123456 OK 127.0.0.1:6379\u003e INFO replication #查看当前角色默认为master # Replication role:master connected_slaves:0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1361 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1361 127.0.0.1:6379\u003e 在slave实现 #在slave上设置master的IP和端口，4.0版之前的指令为slaveof 127.0.0.1:6380\u003e REPLICAOF 127.0.0.1 6379 #仍可使用SLAVEOF MasterIP Port OK 127.0.0.1:6380\u003e #在slave上设置master的密码 127.0.0.1:6379\u003e CONFIG SET masterauth 123456 # Replication #角色变为slave 127.0.0.1:6380\u003e INFO replication # Replication role:slave master_host:127.0.0.1 #指向master master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_read_repl_offset:1515 slave_repl_offset:1515 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1515 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1362 repl_backlog_histlen:154 127.0.0.1:6380\u003e 在master实现 # 添加值 127.0.0.1:6379\u003e set class m48 OK 127.0.0.1:6379\u003e 在slave验证是否同步过来 # 在slave执行 127.0.0.1:6380\u003e get class \"m48\" 127.0.0.1:6380\u003e # 可以看到已经同步成功 master实现 #在master上可以看到所有slave信息 127.0.0.1:6379\u003e info replication # Replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=6380,state=online,offset=1907,lag=0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1907 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1907 127.0.0.1:6379\u003e 删除主从同步 在slave实现 # 在从节点执行 REPLICAOF NO ONE 指令可以取消主从复制 #取消复制,在slave上执行REPLICAOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave 上已有的数据 127.0.0.1:6380\u003e REPLICAOF no one 验证同步 查看master日志 [root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6379.log 945:M 13 Dec 2022 22:27:17.550 * Synchronization with replica 127.0.0.1:6380 succeeded 945:M 13 Dec 2022 22:42:59.410 # Connection with replica 127.0.0.1:6380 lost. 945:M 13 Dec 2022 22:46:34.373 * Replica 127.0.0.1:6380 asks for synchronization 945:M 13 Dec 2022 22:46:34.373 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for '1200062e6b1065421dec8531ca2d96776029ab3d', my replication IDs are 'f945fd1714d8d3b78a149c8b2e0d57567ee6cb77' and '0000000000000000000000000000000000000000') 945:M 13 Dec 2022 22:46:34.373 * Starting BGSAVE for SYNC with target: disk 945:M 13 Dec 2022 22:46:34.374 * Background saving started by pid 1690 1690:C 13 Dec 2022 22:46:34.376 * DB saved on disk 1690:C 13 Dec 2022 22:46:34.377 * RDB: 2 MB of memory used by copy-on-write 945:M 13 Dec 2022 22:46:34.435 * Background saving terminated with success 945:M 13 Dec 2022 22:46:34.435 * Synchronization with replica 127.0.0.1:6380 succeeded 查看slave日志 [root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6380.log 946:S 13 Dec 2022 22:46:34.436 * MASTER \u003c-\u003e REPLICA sync: Finished with success 946:S 13 Dec 2022 22:46:34.437 * Background append only file rewriting started by pid 1691 946:S 13 Dec 2022 22:46:34.470 * AOF rewrite child asks to stop sending diffs. 1691:C 13 Dec 2022 22:46:34.470 * Parent agreed to stop sending diffs. Finalizing AOF... 1691:C 13 Dec 2022 22:46:34.470 * Concatenating 0.00 MB of AOF diff received from parent. 1691:C 13 Dec 2022 22:46:34.470 * SYNC append only file rewrite performed 1691:C 13 Dec 2022 22:46:34.471 * AOF rewrite: 2 MB of memory used by copy-on-write 946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite terminated with success 946:S 13 Dec 2022 22:46:34.536 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB) 946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite finished successfully 修改slave配置文件 [root@centos7-master ~]# vim /usr/local/src/redis/etc/redis6380.conf # replicaof replicaof 127.0.0.1 6379 #指定master的IP和端口号，我这里在同一台机器上安装了多实例 # masterauth masterauth 123456 #如果密码需要设置 systemctl restart redis #在master上查看状态 127.0.0.1:6379\u003e info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=3307,lag=1 slave1:ip=127.0.0.1,port=6381,state=online,offset=3307,lag=1 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:3307 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:3307 127.0.0.1:6379\u003e #停止master的redis服务：systemctl stop redis,在slave上可以观察到以下现象 127.0.0.1:6381\u003e info replication # Replication role:slave master_host:192.168.1.104 master_port:6379 master_link_status:down #显示down，表示无法连接master master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_read_repl_offset:84 slave_repl_offset:84 master_link_down_since_seconds:14 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:f6eefc841166e73282b4bab58527081653ddb0d1 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:84 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:15 repl_backlog_histlen:70 127.0.0.1:6381\u003e slave 只读状态 验证Slave节点为只读状态, 不支持写入 127.0.0.1:6381\u003e set ll aa (error) READONLY You can't write against a read only replica. 127.0.0.1:6381\u003e Redis实现哨兵架构 以下案例实现一主两从的基于哨兵的高可用Redis架构\n先实现主从架构 哨兵的前提是已经实现了Redis的主从复制 注意: master 的配置文件中masterauth 和slave 都必须相同 所有主从节点的 redis.conf 中关健配置 范例: 准备主从环境配置\n#在所有主从节点执行 vim redis.conf bind 0.0.0.0 masterauth \"123456\" requirepass \"123456\" #或者非交互执行 [root@centos8 ~]#sed -i -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e 's/^# masterauth .*/masterauth 123456/' -e 's/^# requirepass .*/requirepass 123456/' /etc/redis.conf #在所有从节点执行 [root@centos8 ~]#echo \"replicaof 192.168.32.133 6379\" \u003e\u003e /etc/redis.conf #在所有主从节点执行 [root@centos8 ~]#systemctl enable --now redis 配置slave1 [root@redis-slave1 ~]#redis-cli -a 123456 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 127.0.0.1:6379\u003e REPLICAOF 192.168.32.133 6379 OK 127.0.0.1:6379\u003e CONFIG SET masterauth \"123456\" OK 配置slave2 [root@redis-slave2 ~]#redis-cli -a 123456 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 127.0.0.1:6379\u003e REPLICAOF 192.168.32.133 6379 OK 127.0.0.1:6379\u003e CONFIG SET masterauth \"123456\" OK 编辑哨兵配置\nsentinel配置 Sentinel实际上是一个特殊的redis服务器,有些redis指令支持,但很多指令并不支持.默认监听在 26379/tcp端口. 哨兵服务可以和Redis服务器分开部署在不同主机，但为了节约成本一般会部署在一起 所有redis节点使用相同的以下示例的配置文件 #如果是编译安装，在源码目录有sentinel.conf，复制到安装目录即可， 如:/usr/local/src/redis/etc/sentinel.conf [root@centos8 ~]#cp redis-6.2.5/sentinel.conf /usr/local/src/redis/etc/ [root@centos8 ~]#chown redis.redis /usr/local/src/redis/etc/sentinel.conf [root@centos8 ~]#vim /etc/redis-sentinel.conf bind 0.0.0.0 port 26379 daemonize yes pidfile \"redis-sentinel.pid\" logfile \"sentinel_26379.log\" dir \"/tmp\" #工作目录 sentinel monitor mymaster 10.0.0.8 6379 2 #mymaster是集群的名称，此行指定当前mymaster集群中master服务器的地址和端口 #2为法定人数限制(quorum)，即有几个sentinel认为master down了就进行故障转移，一般此值是所有 sentinel节点(一般总数是\u003e=3的 奇数,如:3,5,7等)的一半以上的整数值，比如，总数是3，即3/2=1.5， 取整为2,是master的ODOWN客观下线的依据 sentinel auth-pass mymaster 123456 #mymaster集群中master的密码，注意此行要在上面行的下面 sentinel down-after-milliseconds mymaster 30000 #判断mymaster集群中所有节点的主观下线(SDOWN)的时间，单位：毫秒，建议3000 sentinel parallel-syncs mymaster 1 #发生故障转移后，可以同时向新master同步数据的slave的数量，数字越小总同步时间越长，但可以减轻新 master的负载压力 sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间，单位：毫秒 sentinel deny-scripts-reconfig yes #禁止修改脚本 logfile /var/log/redis/sentinel.log 三个哨兵服务器的配置都如下 port 26379 daemonize no pidfile \"/var/run/redis-sentinel.pid\" logfile \"/var/log/redis/sentinel.log\" dir \"/tmp\" sentinel monitor mymaster 192.168.32.133 6379 2 #修改此行 sentinel auth-pass mymaster 123456 #增加此行 sentinel down-after-milliseconds mymaster 3000 #修改此行 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes #注意此行自动生成必须唯一,一般不需要修改，如果相同则修改此值需重启redis和sentinel服务 sentinel myid 50547f34ed71fd48c197924969937e738a39975b ..... # Generated by CONFIG REWRITE protected-mode no supervised systemd sentinel leader-epoch mymaster 0 sentinel known-replica mymaster 10.0.0.28 6379 sentinel known-replica mymaster 10.0.0.18 6379 sentinel current-epoch 0 启动哨兵服务 将所有哨兵服务器都启动起来 /usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf 将服务写成service文件 vim /lib/systemd/system/redis-sentinel.service [Unit] Description=Redis Sentinel After=network.target [Service] ExecStart=/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf --supervised systemd ExecStop=/bin/kill -s QUIT $MAINPID User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target #注意所有节点的目录权限,否则无法启动服务 [root@redis-master ~]#chown -R redis.redis /usr.local/src/redis/ 验证哨兵服务 查看哨兵服务端口状态,端口26379\n[root@centos8 log]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 511 0.0.0.0:26379 0.0.0.0:* LISTEN 0 511 0.0.0.0:6379 0.0.0.0:* LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 511 [::1]:6379 [::]:* LISTEN 0 128 [::]:22 [::]:* [root@centos8 log]# Sentinel 运维 手动让主节点下线\n127.0.0.1:26379\u003e sentinel failover 范例：手动故障转移\nvim redis.conf replica-priority 10 #指定优先级,值越小sentinel会优先将之选为新的master,默为值为100 systemctl restart redis #或者动态修改 [root@centos8 ~]#redis-cli -a 123456 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 127.0.0.1:6379\u003e CONFIG GET replica-priority 1) \"replica-priority\" 2) \"100\" 127.0.0.1:6379\u003e CONFIG SET replica-priority 99 OK 127.0.0.1:6379\u003e CONFIG GET replica-priority 1) \"replica-priority\" 2) \"99\" [root@centos8 ~]#redis-cli -p 26379 127.0.0.1:26379\u003e sentinel failover mymaster OK 应用程序连接 Sentinel Redis 官方支持多种开发语言的客户端：https://redis.io/clients\n客户端连接 Sentinel 工作原理 客户端获取 Sentinel 节点集合,选举出一个 Sentinel 由这个sentinel 通过masterName 获取master节点信息,客户端通过sentinel get-master-addr-by-name master-name这个api来获取对应主节点信息 客户端发送role指令确认master的信息,验证当前获取的“主节点”是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化 客户端保持和Sentinel节点集合的联系，即订阅Sentinel节点相关频道，时刻获取关于主节点的相关信息,获取新的master 信息变化,并自动连接新的master java 连接Sentinel哨兵 java 客户端连接Redis：https://github.com/xetorthio/jedis/blob/master/pom.xml\npython 连接 Sentinel 哨兵 [root@centos8 ~]#yum -y install python3 python3-redis [root@centos8 ~]#vim sentinel_test.py #!/usr/bin/python3 import redis from redis.sentinel import Sentinel #连接哨兵服务器(主机名也可以用域名) sentinel = Sentinel([('192.168.32.135', 26379), ('192.168.32.133', 26379), ('192.168.32.132', 26379)], socket_timeout=0.5) redis_auth_pass = '123456' #mymaster 是配置哨兵模式的redis集群名称，此为默认值,实际名称按照个人部署案例来填写 #获取主服务器地址 master = sentinel.discover_master('mymaster') print(\"master:\",master) #获取从服务器地址 slave = sentinel.discover_slaves('mymaster') print(\"slave:\",slave) #获取主服务器进行写入 master = sentinel.master_for('mymaster', socket_timeout=0.5, password=redis_auth_pass, db=0) w_ret = master.set('name', 'xy') #输出：True #获取从服务器进行读取（默认是round-roubin） slave = sentinel.slave_for('mymaster', socket_timeout=0.5, password=redis_auth_pass, db=0) r_ret = slave.get('name') print(r_ret) #输出：xy chmod +x sentinel_test.py ./sentinel_test.py master: ('192.168.32.135', 6379) slave: [('192.168.32.133', 6379)] b'xy' Redis Cluster Redis Cluster 介绍 使用哨兵sentinel 只能解决Redis高可用问题，实现Redis的自动故障转移,但仍然无法解决Redis Master 单节点的性能瓶颈问题 为了解决单机性能的瓶颈，提高Redis 服务整体性能，可以使用分布式集群的解决方案 早期 Redis 分布式集群部署方案：\n客户端分区：由客户端程序自己实现写入分配、高可用管理和故障转移等,对客户端的开发实现较为复杂 代理服务：客户端不直接连接Redis,而先连接到代理服务，由代理服务实现相应读写分配，当前代理服务都是第三方实现.此方案中客户端实现无需特殊开发,实现容易,但是代理服务节点仍存有单点故障和性能瓶颈问题。比如：豌豆荚开发的 codis Redis 3.0 版本之后推出无中心架构的 Redis Cluster ，支持多个master节点并行写入和故障的自动转移动能\nRedis cluster 架构 Redis cluster 架构 Redis cluster 需要至少 3个master节点才能实现,slave节点数量不限,当然一般每个master都至少对应的有一个slave节点 如果有三个主节点采用哈希槽 hash slot 的方式来分配16384个槽位 slot 此三个节点分别承担的slot 区间可以是如以下方式分配\n节点M1 0－5460 节点M2 5461－10922 节点M3 10923－16383 Redis cluster的工作原理 数据分区 如果是单机存储的话，直接将数据存放在单机redis就行了。但是如果是集群存储，就需要考虑到数据分区了。\n集群通信 但是寻找槽的过程并不是一次就命中的，比如上图key将要存放在14396槽中，但是并不是一下就锁定了node3节点，可能先去询问node1，然后才访问node3。 而集群中节点之间的通信，保证了最多两次就能命中对应槽所在的节点。因为在每个节点中，都保存了其他节点的信息，知道哪个槽由哪个节点负责。这样即使第一次访问没有命中槽，但是会通知客户端，该槽在哪个节点，这样访问对应节点就能精准命中。\n集群伸缩 集群并不是建立之后，节点数就固定不变的，也会有新的节点加入集群或者集群中的节点下线，这就是集群的扩容和缩容。但是由于集群节点和槽息息相关，所以集群的伸缩也对应了槽和数据的迁移\n集群扩容 当有新的节点准备好加入集群时，这个新的节点还是孤立节点，加入有两种方式。一个是通过集群节点执行命令来和孤立节点握手，另一个则是使用脚本来添加节点。\n集群缩容 故障转移 当从节点走马上任变成主节点之后，就要开始进行替换主节点：\n让该slave节点执行slaveof no one变为master节点 将故障节点负责的槽分配给该节点 向集群中其他节点广播Pong消息，表明已完成故障转移 故障节点重启后，会成为new_master的slave节点 实战案例 基于Redis 5 以上版本的 redis cluster 部署 官方文档：https://redis.io/topics/cluster-tutorial\n创建 redis cluster集群的环境准备 每个Redis 节点采用相同的相同的Redis版本、相同的密码、硬件配置 所有Redis服务器必须没有任何数据 准备六台主机，地址如下： 192.168.32.132 192.168.32.137 192.168.32.140 192.168.32.129 192.168.32.136 192.168.32.138 启用 redis cluster 配置 每个节点安装相同版每个节点修改redis配置，必须开启cluster功能的参数\nvim /etc/redis.conf bind 0.0.0.0 masterauth 123456 #建议配置，否则后期的master和slave主从复制无法成功，还需再配置 requirepass 123456 cluster-enabled yes #取消此行注释,必须开启集群，开启后 redis 进程会有cluster标识 cluster-config-file nodes-6379.conf #取消此行注释,此为集群状态数据文件,记录主从关系 及slot范围信息,由redis cluster 集群自动创建和维护 cluster-require-full-coverage no #默认值为yes,设为no可以防止一个节点不可用导致整 个cluster不可用 以下方式二选一\n执行下面命令,批量修改 sed -i.bak -e 's/bind 127.0.0.1/bind 0.0.0.0/' -e '/masterauth/a masterauth 123456' -e '/# requirepass/a requirepass 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /etc/redis.conf 如果是编译安装可以执行下面操作 sed -i.bak -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /usr/local/src/redis/etc/redis.conf 开机启动redis\nsystemctl enable --now redis # 修改完配置文件重启redis systemctl restart redis 验证当前Redis服务状态：\n#开启了16379的cluster的端口,实际的端口=redis port + 10000 [root@centos7 ~]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 511 *:16379 *:* LISTEN 0 511 *:6379 *:* LISTEN 0 128 [::]:22 [::]:* LISTEN 0 100 [::1]:25 [::]:* LISTEN 0 511 [::1]:16379 [::]:* LISTEN 0 511 [::1]:6379 [::]:* [root@centos7 ~]# 创建集群 #命令redis-cli的选项 --cluster-replicas 1 表示每个master对应一个slave节点 # 默认前三个为主节点 [root@centos8 etc]# redis-cli -a 123456 --cluster create 192.168.32.132:6379 192.168.32.137:6379 192.168.32.140:6379 192.168.32.129:6379 192.168.32.136:6379 192.168.32.138:6379 --cluster-replicas 1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Performing hash slots allocation on 6 nodes... Master[0] -\u003e Slots 0 - 5460 Master[1] -\u003e Slots 5461 - 10922 Master[2] -\u003e Slots 10923 - 16383 Adding replica 192.168.32.136:6379 to 192.168.32.132:6379 Adding replica 192.168.32.138:6379 to 192.168.32.137:6379 Adding replica 192.168.32.129:6379 to 192.168.32.140:6379 M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 replicates 46b54e8298e11e77450e232c9a0ee057b362191a Can I set the above configuration? (type 'yes' to accept): yes \u003e\u003e\u003e Nodes configuration updated \u003e\u003e\u003e Assign a different config epoch to each node \u003e\u003e\u003e Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# 验证集群 查看主从状态 127.0.0.1:6379\u003e info replication # Replication role:master connected_slaves:1 slave0:ip=192.168.32.136,port=6379,state=online,offset=98,lag=1 master_failover_state:no-failover master_replid:b1bd51213722f38a83c8bb525e8a74e62392a161 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:98 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:98 127.0.0.1:6379\u003e 验证集群状态\n127.0.0.1:6379\u003e CLUSTER INFO cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 # 节点数 cluster_size:3 # 三个集群 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:210 cluster_stats_messages_pong_sent:210 cluster_stats_messages_sent:420 cluster_stats_messages_ping_received:205 cluster_stats_messages_pong_received:210 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:420 127.0.0.1:6379\u003e #查看任意节点的集群状态 [root@centos8 ~]# redis-cli -a 123456 --cluster info 192.168.32.137:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.32.137:6379 (46b54e82...) -\u003e 0 keys | 5462 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u003e 0 keys | 5461 slots | 1 slaves. 192.168.32.132:6379 (658dd91e...) -\u003e 0 keys | 5461 slots | 1 slaves. [OK] 0 keys in 3 masters. 0.00 keys per slot on average. [root@centos8 ~]# 查看对应关系 [root@centos8 ~]# redis-cli -a 123456 CLUSTER NODES Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379@16379 slave f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 0 1671364792207 3 connected 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379@16379 myself,master - 0 1671364792000 1 connected 0-5460 f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379@16379 master - 0 1671364792000 3 connected 10923-16383 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379@16379 master - 0 1671364793216 2 connected 5461-10922 f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379@16379 slave 658dd91e4b51bf06b161e6903d4084c77abd195d 0 1671364793000 1 connected eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379@16379 slave 46b54e8298e11e77450e232c9a0ee057b362191a 0 1671364792000 2 connected [root@centos8 ~]# 测试集群写入数据 redis cluster 写入key #经过算法计算，当前key的槽位需要写入指定的node [root@centos8 ~]# redis-cli -a 123456 set k1 v1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. (error) MOVED 12706 192.168.32.140:6379 #槽位不在当前node所以无法写入 [root@centos8 ~]# #指定槽位对应node可写入 [root@centos8 ~]# redis-cli -h 192.168.32.140 -a 123456 set k1 v1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. OK [root@centos8 ~]# #对应的slave节点可以KEYS *,但GET k1失败,可以到master上执行GET k1 [root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 get k1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. (error) MOVED 12706 192.168.32.140:6379 [root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 keys \"*\" Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 1) \"k1\" [root@centos8 ~]# Redis cluster 管理 集群扩容 扩容适用场景： 当前客户量激增，现有的Redis cluster架构已经无法满足越来越高的并发访问请求，为解决此问题,新购置两台服务器，要求将其动态添加到现有集群，但不能影响业务的正常访问。 注意: 生产环境一般建议master节点为奇数个,比如:3,5,7,以防止脑裂现象\n添加节点准备 增加Redis 新节点，需要与之前的Redis node版本和配置一致，然后分别再启动两台Redis node，应为一主一从。\n192.168.32.133 主 192.168.32.139 从 # 修改配置文件,主从节点都修改 sed -i.bak -e '/masterauth/a masterauth 123456' -e '/# cluster-enabled yes/a cluster-enabled yes' -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' -e '/cluster-require-full-coverage yes/c cluster-require-full-coverage no' /usr/local/src/redis/etc/redis.conf systemctl restart redis 添加新的master节点到集群\n使用以下命令添加新节点，要添加的新redis节点IP和端口添加到的已有的集群中任意节点的IP:端口 add-node new_host:new_port existing_host:existing_port [--slave --master-id ] #说明： new_host:new_port #指定新添加的主机的IP和端口 existing_host:existing_port #指定已有的集群中任意节点的IP和端口 Redis 3/4 版本的添加命令： #把新的Redis 节点192.168.32.133添加到当前Redis集群当中。 [root@redis-node1 ~]#redis-trib.rb add-node 192.168.32.133:6379 192.168.32.132:6379 Redis 5 以上版本的添加命令： #将一台新的主机加入集群 [root@redis-node1 ~]#redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 \u003c当前 任意集群节点\u003e:6379 [root@centos8 data]# redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Adding node 192.168.32.133:6379 to cluster 192.168.32.132:6379 \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. \u003e\u003e\u003e Send CLUSTER MEET to node 192.168.32.133:6379 to make it join the cluster. [OK] New node added correctly. [root@centos8 data]# 在新的master上重新分配槽位 新的node节点加到集群之后,默认是master节点，但是没有slots，需要重新分配,否则没有槽位将无法访问 注意: 重新分配槽位需要清空数据,所以需要先备份数据,扩展后再恢复数据 Redis 3/4 版本命令: [root@redis-node1 ~]# redis-trib.rb check 10.0.0.67:6379 #当前状态 [root@redis-node1 ~]# redis-trib.rb reshard \u003c任意节点\u003e:6379 #重新分片 [root@redis-node1 ~]# redis-trib.rb fix 10.0.0.67:6379 #如果迁移失败使用此命令修复集群 Redis 5以上版本命令： [root@redis-node1 ~]#redis-cli -a 123456 --cluster reshard \u003c当前任意集群节点\u003e:6379 [root@centos8 data]# redis-cli -a 123456 --cluster reshard 192.168.32.133:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.133:6379) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots: (0 slots) master S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 4096 # 复制新加入的节点的ID，即192.168.32.133的节点ID What is the receiving node ID? 77cfc3429c8b470331520074faea7c3a21f77d1f Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1: all # 选择all Do you want to proceed with the proposed reshard plan (yes/no)? yes 为新的master指定新的slave节点 当前Redis集群中新的master节点存单点问题,还需要给其添加一个对应slave节点，实现高可用功能 有两种方式： 方法1：在新加节点到集群时，直接将之设置为slave Redis 3/4 添加命令\nredis-trib.rb add-node --slave --master-id 750cab050bc81f2655ed53900fd43d2e64423333 192.168.32.139:6379 \u003c任意集群节点\u003e:6379 Redis 5 以上版本添加命令：\nredis-cli -a 123456 --cluster add-node 192.168.32.139:6379 \u003c任意集群节点\u003e:6379 -- cluster-slave --cluster-master-id d6e2eca6b338b717923f64866bd31d42e52edc98 范例：\n# 查看当前状态 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u003e 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u003e 0 keys | 4096 slots | 0 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u003e 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u003e 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# #直接加为slave节点 [root@centos8 ~]# redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 192.168.32.132:6379 --cluster-slave --cluster-master-id 77cfc3429c8b470331520074faea7c3a21f77d1f # 验证 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u003e 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u003e 0 keys | 4096 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u003e 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u003e 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. 集群缩容 缩容适用场景： 随着业务萎缩用户量下降明显,和领导商量决定将现有Redis集群的8台主机中下线两台主机挪做它用,缩容后性能仍能满足当前业务需求 删除节点过程： 扩容时是先添加node到集群，然后再分配槽位，而缩容时的操作相反，是先将被要删除的node上的槽位迁移到集群中的其他node上，然后 才能再将其从集群中删除，如果一个node上的槽位没有被完全迁移空，删除该node时也会提示有数据出错导致无法删除。\n迁移要删除的master节点上面的槽位到其它master 注意: 被迁移Redis master源服务器必须保证没有数据，否则迁移报错并会被强制中断。 Redis 3/4 版本命令\n[root@redis-node1 ~]# redis-trib.rb reshard 10.0.0.8:6379 [root@redis-node1 ~]# redis-trib.rb fix 10.0.0.8:6379 #如果迁移失败使用此命令修复集群 Redis 5版本以上命令\n# 查看当前状态 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u003e 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u003e 0 keys | 4096 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u003e 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u003e 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# #连接到任意集群节点，#最后1365个slot从192.168.32.133移动到第一个master节点192.168.32.132上 [root@centos8 ~]# redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 1356 #共4096/3分别给其它三个master节点 What is the receiving node ID? 658dd91e4b51bf06b161e6903d4084c77abd195d # master id Please enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs. Source node #1: 77cfc3429c8b470331520074faea7c3a21f77d1f # 删除ID，192.168.32.133的ID Source node #2: done Do you want to proceed with the proposed reshard plan (yes/no)? yes # redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 该命令在执行两次 从集群中删除服务器 上面步骤完成后,槽位已经迁移走，但是节点仍然还属于集群成员，因此还需从集群删除该节点 注意: 删除服务器前,必须清除主机上面的槽位,否则会删除主机失败 Redis 3/4命令：\n[root@s~]#redis-trib.rb del-node \u003c任意集群节点的IP\u003e:6379 dfffc371085859f2858730e1f350e9167e287073 #dfffc371085859f2858730e1f350e9167e287073 是删除节点的ID \u003e\u003e\u003e Removing node dfffc371085859f2858730e1f350e9167e287073 from cluster 192.168.7.102:6379 \u003e\u003e\u003e Sending CLUSTER FORGET messages to the cluster... \u003e\u003e\u003e SHUTDOWN the node. Redis 5以上版本命令：\n[root@redis-node1 ~]#redis-cli -a 123456 --cluster del-node \u003c任意集群节点的IP\u003e:6379 cb028b83f9dc463d732f6e76ca6bbcd469d948a7 #cb028b83f9dc463d732f6e76ca6bbcd469d948a7是删除节点的ID 范例\n# 查看节点信息 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u003e 0 keys | 8164 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u003e 0 keys | 28 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u003e 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u003e 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-6826],[10923-12259] (8164 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[12260-12287] (28 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# # 删除192.168.32.133节点 [root@centos8 ~]# redis-cli -a 123456 --cluster del-node 192.168.32.132:6379 77cfc3429c8b470331520074faea7c3a21f77d1f Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Removing node 77cfc3429c8b470331520074faea7c3a21f77d1f from cluster 192.168.32.132:6379 \u003e\u003e\u003e Sending CLUSTER FORGET messages to the cluster... \u003e\u003e\u003e Sending CLUSTER RESET SOFT to the deleted node. [root@centos8 ~]# 常见面试题 Redis 做什么的,即在哪些场景下使用 如果监控 Redis 是否出现故障 Redis客户端timeout报错突然增加，排查思路是怎样的？ 请简单描述pipeline功能，为什么pipeline功能会提升redis性能? 本地redis-client访问远程Redis服务出错，说出几种常见的错误? key-value的大小超大或单key的qps超高，会对Redis本身造成什么样的影响、会对访问Redis的其他客户端造成什么样的影响？ Zabbix 监控 Redis 哪些监控项 RDB和AOF持久化区别 docker拉取一个Redis如何实现数据持久化保存 Redis 支持哪些数据类型 Redis 如何实现消息队列 描述下常见的redis集群架构有哪些，他们之间的优缺点对比 主从复制工作原理 Redis 如何实现高可用 哨兵工作原理 Redis 集群的工作原理 Redis 集群如果避免脑裂 Redis 集群最少几个节点为什么? Redis的集群槽位多少个 Redis集群中某个节点缺少一个槽位是否能使用 Redis数据写入的时候是怎么在各个节点槽位分配数据的 Redis的数据存储是以什么样的方式存储 Redis集群的各槽位和总槽位之间什么关系 ",
  "wordCount" : "9177",
  "inLanguage": "en",
  "image":"http://oss.itshare.work/itshare-work-images/29.jpg","datePublished": "2022-12-13T22:20:06Z",
  "dateModified": "2022-12-13T22:20:06Z",
  "author":[{
    "@type": "Person",
    "name": "yuan kun"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://gz0854.com/posts/redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Hopeful",
    "logo": {
      "@type": "ImageObject",
      "url": "http://gz0854.com/img/Q.gif"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://gz0854.com/" accesskey="h" title="Hopeful (Alt + H)">
            <img src="http://gz0854.com/img/Q.gif" alt="logo" aria-label="logo"
                 height="35">Hopeful</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://gz0854.com/search" title="🔍 搜索 (Alt &#43; /)" accesskey=/>
                <span>🔍 搜索</span>
                </a>
            </li>
            <li>
                <a href="http://gz0854.com/" title="🏠 主页">
                <span>🏠 主页</span>
                </a>
            </li>
            <li>
                <a href="http://gz0854.com/posts" title="📚 文章">
                <span>📚 文章</span>
                </a>
            </li>
            <li>
                <a href="http://gz0854.com/tags" title="🧩 标签">
                <span>🧩 标签</span>
                </a>
            </li>
            <li>
                <a href="http://gz0854.com/archives/" title="⏱️ 时间轴">
                <span>⏱️ 时间轴</span>
                </a>
            </li>
            <li>
                <a href="http://gz0854.com/about" title="🙋🏻‍♂️ 关于">
                <span>🙋🏻‍♂️ 关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="http://gz0854.com/">🏠 主页</a>&nbsp;»&nbsp;<a href="http://gz0854.com/posts/">📚文章</a></div>
            <h1 class="post-title">
                Redis集群和高可用
            </h1>
            <div class="post-description">
                Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2022-12-13
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>9177字
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>19分钟
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>yuan kun
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="http://gz0854.com/tags/redis/" style="color: var(--secondary)!important;">Redis</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "http://gz0854.com/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId:  null , 
                                region:  null , 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="http://oss.itshare.work/itshare-work-images/29.jpg" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">文章目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e7%ae%80%e4%bb%8b" aria-label="简介">简介</a></li>
                <li>
                    <a href="#%e4%b8%bb%e4%bb%8e%e5%a4%8d%e5%88%b6%e5%ae%9e%e7%8e%b0" aria-label="主从复制实现">主从复制实现</a><ul>
                        
                <li>
                    <a href="#%e4%b8%bb%e4%bb%8e%e5%91%bd%e4%bb%a4%e9%85%8d%e7%bd%ae" aria-label="主从命令配置">主从命令配置</a><ul>
                        
                <li>
                    <a href="#%e5%90%af%e7%94%a8%e4%b8%bb%e4%bb%8e%e5%90%8c%e6%ad%a5" aria-label="启用主从同步">启用主从同步</a></li>
                <li>
                    <a href="#%e5%88%a0%e9%99%a4%e4%b8%bb%e4%bb%8e%e5%90%8c%e6%ad%a5" aria-label="删除主从同步">删除主从同步</a></li>
                <li>
                    <a href="#%e9%aa%8c%e8%af%81%e5%90%8c%e6%ad%a5" aria-label="验证同步">验证同步</a></li>
                <li>
                    <a href="#%e4%bf%ae%e6%94%b9slave%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6" aria-label="修改slave配置文件">修改slave配置文件</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#redis%e5%ae%9e%e7%8e%b0%e5%93%a8%e5%85%b5%e6%9e%b6%e6%9e%84" aria-label="Redis实现哨兵架构">Redis实现哨兵架构</a></li>
                <li>
                    <a href="#%e5%ba%94%e7%94%a8%e7%a8%8b%e5%ba%8f%e8%bf%9e%e6%8e%a5-sentinel" aria-label="应用程序连接 Sentinel">应用程序连接 Sentinel</a><ul>
                        
                <li>
                    <a href="#%e5%ae%a2%e6%88%b7%e7%ab%af%e8%bf%9e%e6%8e%a5-sentinel-%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86" aria-label="客户端连接 Sentinel 工作原理">客户端连接 Sentinel 工作原理</a></li>
                <li>
                    <a href="#java-%e8%bf%9e%e6%8e%a5sentinel%e5%93%a8%e5%85%b5" aria-label="java 连接Sentinel哨兵">java 连接Sentinel哨兵</a></li>
                <li>
                    <a href="#python-%e8%bf%9e%e6%8e%a5-sentinel-%e5%93%a8%e5%85%b5" aria-label="python 连接 Sentinel 哨兵">python 连接 Sentinel 哨兵</a></li></ul>
                </li>
                <li>
                    <a href="#redis-cluster" aria-label="Redis Cluster">Redis Cluster</a><ul>
                        
                <li>
                    <a href="#redis-cluster-%e4%bb%8b%e7%bb%8d" aria-label="Redis Cluster 介绍">Redis Cluster 介绍</a></li>
                <li>
                    <a href="#redis-cluster-%e6%9e%b6%e6%9e%84" aria-label="Redis cluster 架构">Redis cluster 架构</a><ul>
                        
                <li>
                    <a href="#redis-cluster-%e6%9e%b6%e6%9e%84-1" aria-label="Redis cluster 架构">Redis cluster 架构</a></li>
                <li>
                    <a href="#redis-cluster%e7%9a%84%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86" aria-label="Redis cluster的工作原理">Redis cluster的工作原理</a><ul>
                        
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e5%88%86%e5%8c%ba" aria-label="数据分区">数据分区</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e9%80%9a%e4%bf%a1" aria-label="集群通信">集群通信</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e4%bc%b8%e7%bc%a9" aria-label="集群伸缩">集群伸缩</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e6%89%a9%e5%ae%b9" aria-label="集群扩容">集群扩容</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e7%bc%a9%e5%ae%b9" aria-label="集群缩容">集群缩容</a></li>
                <li>
                    <a href="#%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb" aria-label="故障转移">故障转移</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e5%ae%9e%e6%88%98%e6%a1%88%e4%be%8b" aria-label="实战案例">实战案例</a><ul>
                        
                <li>
                    <a href="#%e5%9f%ba%e4%ba%8eredis-5-%e4%bb%a5%e4%b8%8a%e7%89%88%e6%9c%ac%e7%9a%84-redis-cluster-%e9%83%a8%e7%bd%b2" aria-label="基于Redis 5 以上版本的 redis cluster 部署">基于Redis 5 以上版本的 redis cluster 部署</a><ul>
                        
                <li>
                    <a href="#%e5%88%9b%e5%bb%ba-redis-cluster%e9%9b%86%e7%be%a4%e7%9a%84%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87" aria-label="创建 redis cluster集群的环境准备">创建 redis cluster集群的环境准备</a></li>
                <li>
                    <a href="#%e5%90%af%e7%94%a8-redis-cluster-%e9%85%8d%e7%bd%ae" aria-label="启用 redis cluster 配置">启用 redis cluster 配置</a></li>
                <li>
                    <a href="#%e5%88%9b%e5%bb%ba%e9%9b%86%e7%be%a4" aria-label="创建集群">创建集群</a></li>
                <li>
                    <a href="#%e9%aa%8c%e8%af%81%e9%9b%86%e7%be%a4" aria-label="验证集群">验证集群</a></li>
                <li>
                    <a href="#%e6%9f%a5%e7%9c%8b%e5%af%b9%e5%ba%94%e5%85%b3%e7%b3%bb" aria-label="查看对应关系">查看对应关系</a></li>
                <li>
                    <a href="#%e6%b5%8b%e8%af%95%e9%9b%86%e7%be%a4%e5%86%99%e5%85%a5%e6%95%b0%e6%8d%ae" aria-label="测试集群写入数据">测试集群写入数据</a></li></ul>
                </li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#redis-cluster-%e7%ae%a1%e7%90%86" aria-label="Redis cluster 管理">Redis cluster 管理</a><ul>
                        
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e6%89%a9%e5%ae%b9-1" aria-label="集群扩容">集群扩容</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e7%bc%a9%e5%ae%b9-1" aria-label="集群缩容">集群缩容</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%b8%b8%e8%a7%81%e9%9d%a2%e8%af%95%e9%a2%98" aria-label="常见面试题">常见面试题</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h1 id="简介">简介<a hidden class="anchor" aria-hidden="true" href="#简介">#</a></h1>
<p>Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题.</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671327877294.png" alt="1671327877294"  />
</p>
<h1 id="主从复制实现">主从复制实现<a hidden class="anchor" aria-hidden="true" href="#主从复制实现">#</a></h1>
<h2 id="主从命令配置">主从命令配置<a hidden class="anchor" aria-hidden="true" href="#主从命令配置">#</a></h2>
<p><img loading="lazy" src="/posts.images/image.assets/1670942266531.png" alt="1670942266531"  />
</p>
<p>当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则的话，由于延迟等问题，部署的主节点Redis服务应该要避免自动启动。</p>
<p>参考案例: 导致主从服务器数据全部丢失</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>1.假设节点A为主服务器，并且关闭了持久化。并且节点B和节点C从节点A复制数据
</span></span><span style="display:flex;"><span>2.节点A崩溃，然后由自动拉起服务重启了节点A.由于节点A的持久化被关闭了，所以重启之后没有任何数据
</span></span><span style="display:flex;"><span>3.节点B和节点C将从节点A复制数据，但是A的数据是空的，于是就把自身保存的数据副本删除。
</span></span></code></pre></div><p>在关闭主服务器上的持久化，并同时开启自动拉起进程的情况下，即便使用Sentinel来实现Redis的高可用性，也是非常危险的。因为主服务器可能拉起得非常快，以至于Sentinel在配置的心跳时间间隔内没有检测到主服务器已被重启，然后还是会执行上面的数据丢失的流程。无论何时，数据安全都是极其重要的，所以应该禁止主服务器关闭持久化的同时自动启动。</p>
<h3 id="启用主从同步">启用主从同步<a hidden class="anchor" aria-hidden="true" href="#启用主从同步">#</a></h3>
<p>Redis Server 默认为 master节点，如果要配置为从节点,需要指定master服务器的IP,端口及连接密码在从节点执行 REPLICAOF MASTER_IP PORT 指令可以启用主从同步复制功能,早期版本使用 SLAVEOF指令</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:6379&gt; REPLICAOF MASTER_IP PORT #新版推荐使用
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; SLAVEOF MasterIP Port #旧版使用，将被淘汰
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG SET masterauth &lt;masterpass&gt;
</span></span></code></pre></div><ul>
<li>在master实现</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:6379&gt; AUTH 123456
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; INFO replication #查看当前角色默认为master
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:master
</span></span><span style="display:flex;"><span>connected_slaves:0
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:1361
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:1
</span></span><span style="display:flex;"><span>repl_backlog_histlen:1361
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; 
</span></span></code></pre></div><ul>
<li>在slave实现</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#在slave上设置master的IP和端口，4.0版之前的指令为slaveof
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; REPLICAOF 127.0.0.1 6379  #仍可使用SLAVEOF MasterIP Port
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#在slave上设置master的密码
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG SET masterauth 123456
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># Replication #角色变为slave
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; INFO replication
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:slave
</span></span><span style="display:flex;"><span>master_host:127.0.0.1  #指向master
</span></span><span style="display:flex;"><span>master_port:6379
</span></span><span style="display:flex;"><span>master_link_status:up
</span></span><span style="display:flex;"><span>master_last_io_seconds_ago:1
</span></span><span style="display:flex;"><span>master_sync_in_progress:0
</span></span><span style="display:flex;"><span>slave_read_repl_offset:1515
</span></span><span style="display:flex;"><span>slave_repl_offset:1515
</span></span><span style="display:flex;"><span>slave_priority:100
</span></span><span style="display:flex;"><span>slave_read_only:1
</span></span><span style="display:flex;"><span>replica_announced:1
</span></span><span style="display:flex;"><span>connected_slaves:0
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:1515
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:1362
</span></span><span style="display:flex;"><span>repl_backlog_histlen:154
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; 
</span></span></code></pre></div><ul>
<li>在master实现</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 添加值
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; set class m48
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt;
</span></span></code></pre></div><ul>
<li>在slave验证是否同步过来</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 在slave执行
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; get class
</span></span><span style="display:flex;"><span>&#34;m48&#34;
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># 可以看到已经同步成功
</span></span></code></pre></div><ul>
<li>master实现</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#在master上可以看到所有slave信息
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; info replication
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:master
</span></span><span style="display:flex;"><span>connected_slaves:1
</span></span><span style="display:flex;"><span>slave0:ip=127.0.0.1,port=6380,state=online,offset=1907,lag=0
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:1907
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:1
</span></span><span style="display:flex;"><span>repl_backlog_histlen:1907
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; 
</span></span></code></pre></div><h3 id="删除主从同步">删除主从同步<a hidden class="anchor" aria-hidden="true" href="#删除主从同步">#</a></h3>
<ul>
<li>在slave实现</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 在从节点执行 REPLICAOF NO ONE 指令可以取消主从复制
</span></span><span style="display:flex;"><span>#取消复制,在slave上执行REPLICAOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave
</span></span><span style="display:flex;"><span>上已有的数据
</span></span><span style="display:flex;"><span>127.0.0.1:6380&gt; REPLICAOF no one
</span></span></code></pre></div><h3 id="验证同步">验证同步<a hidden class="anchor" aria-hidden="true" href="#验证同步">#</a></h3>
<ul>
<li>查看master日志</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6379.log 
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:27:17.550 * Synchronization with replica 127.0.0.1:6380 succeeded
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:42:59.410 # Connection with replica 127.0.0.1:6380 lost.
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.373 * Replica 127.0.0.1:6380 asks for synchronization
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.373 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for &#39;1200062e6b1065421dec8531ca2d96776029ab3d&#39;, my replication IDs are &#39;f945fd1714d8d3b78a149c8b2e0d57567ee6cb77&#39; and &#39;0000000000000000000000000000000000000000&#39;)
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.373 * Starting BGSAVE for SYNC with target: disk
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.374 * Background saving started by pid 1690
</span></span><span style="display:flex;"><span>1690:C 13 Dec 2022 22:46:34.376 * DB saved on disk
</span></span><span style="display:flex;"><span>1690:C 13 Dec 2022 22:46:34.377 * RDB: 2 MB of memory used by copy-on-write
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.435 * Background saving terminated with success
</span></span><span style="display:flex;"><span>945:M 13 Dec 2022 22:46:34.435 * Synchronization with replica 127.0.0.1:6380 succeeded
</span></span></code></pre></div><ul>
<li>查看slave日志</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6380.log
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.436 * MASTER &lt;-&gt; REPLICA sync: Finished with success
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.437 * Background append only file rewriting started by pid 1691
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.470 * AOF rewrite child asks to stop sending diffs.
</span></span><span style="display:flex;"><span>1691:C 13 Dec 2022 22:46:34.470 * Parent agreed to stop sending diffs. Finalizing AOF...
</span></span><span style="display:flex;"><span>1691:C 13 Dec 2022 22:46:34.470 * Concatenating 0.00 MB of AOF diff received from parent.
</span></span><span style="display:flex;"><span>1691:C 13 Dec 2022 22:46:34.470 * SYNC append only file rewrite performed
</span></span><span style="display:flex;"><span>1691:C 13 Dec 2022 22:46:34.471 * AOF rewrite: 2 MB of memory used by copy-on-write
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite terminated with success
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.536 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)
</span></span><span style="display:flex;"><span>946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite finished successfully
</span></span></code></pre></div><h3 id="修改slave配置文件">修改slave配置文件<a hidden class="anchor" aria-hidden="true" href="#修改slave配置文件">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@centos7-master ~]# vim /usr/local/src/redis/etc/redis6380.conf 
</span></span><span style="display:flex;"><span># replicaof &lt;masterip&gt; &lt;masterport&gt;
</span></span><span style="display:flex;"><span>replicaof 127.0.0.1 6379 #指定master的IP和端口号，我这里在同一台机器上安装了多实例
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># masterauth &lt;master-password&gt;
</span></span><span style="display:flex;"><span>masterauth 123456 #如果密码需要设置
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart redis
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#在master上查看状态
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; info replication
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:master
</span></span><span style="display:flex;"><span>connected_slaves:2
</span></span><span style="display:flex;"><span>slave0:ip=127.0.0.1,port=6380,state=online,offset=3307,lag=1
</span></span><span style="display:flex;"><span>slave1:ip=127.0.0.1,port=6381,state=online,offset=3307,lag=1
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:3307
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:1
</span></span><span style="display:flex;"><span>repl_backlog_histlen:3307
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#停止master的redis服务：systemctl stop redis,在slave上可以观察到以下现象
</span></span><span style="display:flex;"><span>127.0.0.1:6381&gt; info replication
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:slave
</span></span><span style="display:flex;"><span>master_host:192.168.1.104
</span></span><span style="display:flex;"><span>master_port:6379
</span></span><span style="display:flex;"><span>master_link_status:down   #显示down，表示无法连接master
</span></span><span style="display:flex;"><span>master_last_io_seconds_ago:-1
</span></span><span style="display:flex;"><span>master_sync_in_progress:0
</span></span><span style="display:flex;"><span>slave_read_repl_offset:84
</span></span><span style="display:flex;"><span>slave_repl_offset:84
</span></span><span style="display:flex;"><span>master_link_down_since_seconds:14
</span></span><span style="display:flex;"><span>slave_priority:100
</span></span><span style="display:flex;"><span>slave_read_only:1
</span></span><span style="display:flex;"><span>replica_announced:1
</span></span><span style="display:flex;"><span>connected_slaves:0
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:f6eefc841166e73282b4bab58527081653ddb0d1
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:84
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:15
</span></span><span style="display:flex;"><span>repl_backlog_histlen:70
</span></span><span style="display:flex;"><span>127.0.0.1:6381&gt; 
</span></span></code></pre></div><ul>
<li>slave 只读状态
验证Slave节点为只读状态, 不支持写入</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:6381&gt; set ll aa
</span></span><span style="display:flex;"><span>(error) READONLY You can&#39;t write against a read only replica.
</span></span><span style="display:flex;"><span>127.0.0.1:6381&gt; 
</span></span></code></pre></div><h1 id="redis实现哨兵架构">Redis实现哨兵架构<a hidden class="anchor" aria-hidden="true" href="#redis实现哨兵架构">#</a></h1>
<p>以下案例实现一主两从的基于哨兵的高可用Redis架构</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671283453244.png" alt="1671283453244"  />
</p>
<ul>
<li>先实现主从架构</li>
</ul>
<p>哨兵的前提是已经实现了Redis的主从复制
注意: master 的配置文件中masterauth 和slave 都必须相同
所有主从节点的 redis.conf 中关健配置
范例: 准备主从环境配置</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#在所有主从节点执行
</span></span><span style="display:flex;"><span>vim redis.conf
</span></span><span style="display:flex;"><span>bind 0.0.0.0
</span></span><span style="display:flex;"><span>masterauth &#34;123456&#34;
</span></span><span style="display:flex;"><span>requirepass &#34;123456&#34;
</span></span><span style="display:flex;"><span>#或者非交互执行
</span></span><span style="display:flex;"><span>[root@centos8 ~]#sed -i -e &#39;s/bind 127.0.0.1/bind 0.0.0.0/&#39; -e &#39;s/^# masterauth
</span></span><span style="display:flex;"><span>.*/masterauth 123456/&#39; -e &#39;s/^# requirepass .*/requirepass 123456/&#39;
</span></span><span style="display:flex;"><span>/etc/redis.conf
</span></span><span style="display:flex;"><span>#在所有从节点执行
</span></span><span style="display:flex;"><span>[root@centos8 ~]#echo &#34;replicaof 192.168.32.133 6379&#34; &gt;&gt; /etc/redis.conf
</span></span><span style="display:flex;"><span>#在所有主从节点执行
</span></span><span style="display:flex;"><span>[root@centos8 ~]#systemctl enable --now redis
</span></span></code></pre></div><ul>
<li>配置slave1</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-slave1 ~]#redis-cli -a 123456
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface
</span></span><span style="display:flex;"><span>may not be safe.
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; REPLICAOF 192.168.32.133 6379
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG SET masterauth &#34;123456&#34;
</span></span><span style="display:flex;"><span>OK
</span></span></code></pre></div><ul>
<li>配置slave2</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-slave2 ~]#redis-cli -a 123456
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface
</span></span><span style="display:flex;"><span>may not be safe.
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; REPLICAOF 192.168.32.133 6379
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG SET masterauth &#34;123456&#34;
</span></span><span style="display:flex;"><span>OK
</span></span></code></pre></div><ul>
<li>编辑哨兵配置<br>
sentinel配置
Sentinel实际上是一个特殊的redis服务器,有些redis指令支持,但很多指令并不支持.默认监听在
26379/tcp端口.
哨兵服务可以和Redis服务器分开部署在不同主机，但为了节约成本一般会部署在一起
所有redis节点使用相同的以下示例的配置文件</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#如果是编译安装，在源码目录有sentinel.conf，复制到安装目录即可，
</span></span><span style="display:flex;"><span>如:/usr/local/src/redis/etc/sentinel.conf
</span></span><span style="display:flex;"><span>[root@centos8 ~]#cp redis-6.2.5/sentinel.conf /usr/local/src/redis/etc/
</span></span><span style="display:flex;"><span>[root@centos8 ~]#chown redis.redis /usr/local/src/redis/etc/sentinel.conf
</span></span><span style="display:flex;"><span>[root@centos8 ~]#vim /etc/redis-sentinel.conf
</span></span><span style="display:flex;"><span>bind 0.0.0.0
</span></span><span style="display:flex;"><span>port 26379
</span></span><span style="display:flex;"><span>daemonize yes
</span></span><span style="display:flex;"><span>pidfile &#34;redis-sentinel.pid&#34;
</span></span><span style="display:flex;"><span>logfile &#34;sentinel_26379.log&#34;
</span></span><span style="display:flex;"><span>dir &#34;/tmp&#34; #工作目录
</span></span><span style="display:flex;"><span>sentinel monitor mymaster 10.0.0.8 6379 2
</span></span><span style="display:flex;"><span>#mymaster是集群的名称，此行指定当前mymaster集群中master服务器的地址和端口
</span></span><span style="display:flex;"><span>#2为法定人数限制(quorum)，即有几个sentinel认为master down了就进行故障转移，一般此值是所有
</span></span><span style="display:flex;"><span>sentinel节点(一般总数是&gt;=3的 奇数,如:3,5,7等)的一半以上的整数值，比如，总数是3，即3/2=1.5，
</span></span><span style="display:flex;"><span>取整为2,是master的ODOWN客观下线的依据
</span></span><span style="display:flex;"><span>sentinel auth-pass mymaster 123456
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#mymaster集群中master的密码，注意此行要在上面行的下面
</span></span><span style="display:flex;"><span>sentinel down-after-milliseconds mymaster 30000
</span></span><span style="display:flex;"><span>#判断mymaster集群中所有节点的主观下线(SDOWN)的时间，单位：毫秒，建议3000
</span></span><span style="display:flex;"><span>sentinel parallel-syncs mymaster 1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#发生故障转移后，可以同时向新master同步数据的slave的数量，数字越小总同步时间越长，但可以减轻新
</span></span><span style="display:flex;"><span>master的负载压力
</span></span><span style="display:flex;"><span>sentinel failover-timeout mymaster 180000
</span></span><span style="display:flex;"><span>#所有slaves指向新的master所需的超时时间，单位：毫秒
</span></span><span style="display:flex;"><span>sentinel deny-scripts-reconfig yes #禁止修改脚本
</span></span><span style="display:flex;"><span>logfile /var/log/redis/sentinel.log
</span></span></code></pre></div><ul>
<li>三个哨兵服务器的配置都如下</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>port 26379
</span></span><span style="display:flex;"><span>daemonize no
</span></span><span style="display:flex;"><span>pidfile &#34;/var/run/redis-sentinel.pid&#34;
</span></span><span style="display:flex;"><span>logfile &#34;/var/log/redis/sentinel.log&#34;
</span></span><span style="display:flex;"><span>dir &#34;/tmp&#34;
</span></span><span style="display:flex;"><span>sentinel monitor mymaster 192.168.32.133 6379 2 #修改此行
</span></span><span style="display:flex;"><span>sentinel auth-pass mymaster 123456 #增加此行
</span></span><span style="display:flex;"><span>sentinel down-after-milliseconds mymaster 3000 #修改此行
</span></span><span style="display:flex;"><span>sentinel parallel-syncs mymaster 1
</span></span><span style="display:flex;"><span>sentinel failover-timeout mymaster 180000
</span></span><span style="display:flex;"><span>sentinel deny-scripts-reconfig yes
</span></span><span style="display:flex;"><span>#注意此行自动生成必须唯一,一般不需要修改，如果相同则修改此值需重启redis和sentinel服务
</span></span><span style="display:flex;"><span>sentinel myid 50547f34ed71fd48c197924969937e738a39975b
</span></span><span style="display:flex;"><span>.....
</span></span><span style="display:flex;"><span># Generated by CONFIG REWRITE
</span></span><span style="display:flex;"><span>protected-mode no
</span></span><span style="display:flex;"><span>supervised systemd
</span></span><span style="display:flex;"><span>sentinel leader-epoch mymaster 0
</span></span><span style="display:flex;"><span>sentinel known-replica mymaster 10.0.0.28 6379
</span></span><span style="display:flex;"><span>sentinel known-replica mymaster 10.0.0.18 6379
</span></span><span style="display:flex;"><span>sentinel current-epoch 0
</span></span></code></pre></div><ul>
<li>启动哨兵服务
将所有哨兵服务器都启动起来</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf
</span></span></code></pre></div><ul>
<li>将服务写成service文件</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>vim /lib/systemd/system/redis-sentinel.service
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>[Unit]
</span></span><span style="display:flex;"><span>Description=Redis Sentinel
</span></span><span style="display:flex;"><span>After=network.target
</span></span><span style="display:flex;"><span>[Service]
</span></span><span style="display:flex;"><span>ExecStart=/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf --supervised systemd
</span></span><span style="display:flex;"><span>ExecStop=/bin/kill -s QUIT $MAINPID
</span></span><span style="display:flex;"><span>User=redis
</span></span><span style="display:flex;"><span>Group=redis
</span></span><span style="display:flex;"><span>RuntimeDirectory=redis
</span></span><span style="display:flex;"><span>RuntimeDirectoryMode=0755
</span></span><span style="display:flex;"><span>[Install]
</span></span><span style="display:flex;"><span>WantedBy=multi-user.target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#注意所有节点的目录权限,否则无法启动服务
</span></span><span style="display:flex;"><span>[root@redis-master ~]#chown -R redis.redis /usr.local/src/redis/
</span></span></code></pre></div><ul>
<li>验证哨兵服务</li>
</ul>
<p>查看哨兵服务端口状态,端口26379</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@centos8 log]# ss -ntl
</span></span><span style="display:flex;"><span>State            Recv-Q           Send-Q                     Local Address:Port                       Peer Address:Port           Process           
</span></span><span style="display:flex;"><span>LISTEN           0                511                              0.0.0.0:26379                           0.0.0.0:*                                
</span></span><span style="display:flex;"><span>LISTEN           0                511                              0.0.0.0:6379                            0.0.0.0:*                                
</span></span><span style="display:flex;"><span>LISTEN           0                128                              0.0.0.0:22                              0.0.0.0:*                                
</span></span><span style="display:flex;"><span>LISTEN           0                511                                [::1]:6379                               [::]:*                                
</span></span><span style="display:flex;"><span>LISTEN           0                128                                 [::]:22                                 [::]:*                                
</span></span><span style="display:flex;"><span>[root@centos8 log]# 
</span></span></code></pre></div><ul>
<li>Sentinel 运维</li>
</ul>
<p>手动让主节点下线</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:26379&gt; sentinel failover &lt;masterName&gt;
</span></span></code></pre></div><p>范例：手动故障转移</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>vim redis.conf
</span></span><span style="display:flex;"><span>replica-priority 10 #指定优先级,值越小sentinel会优先将之选为新的master,默为值为100
</span></span><span style="display:flex;"><span>systemctl restart redis
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#或者动态修改
</span></span><span style="display:flex;"><span>[root@centos8 ~]#redis-cli -a 123456
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface
</span></span><span style="display:flex;"><span>may not be safe.
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG GET replica-priority
</span></span><span style="display:flex;"><span>1) &#34;replica-priority&#34;
</span></span><span style="display:flex;"><span>2) &#34;100&#34;
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG SET replica-priority 99
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; CONFIG GET replica-priority
</span></span><span style="display:flex;"><span>1) &#34;replica-priority&#34;
</span></span><span style="display:flex;"><span>2) &#34;99&#34;
</span></span><span style="display:flex;"><span>[root@centos8 ~]#redis-cli -p 26379
</span></span><span style="display:flex;"><span>127.0.0.1:26379&gt; sentinel failover mymaster
</span></span><span style="display:flex;"><span>OK
</span></span></code></pre></div><h1 id="应用程序连接-sentinel">应用程序连接 Sentinel<a hidden class="anchor" aria-hidden="true" href="#应用程序连接-sentinel">#</a></h1>
<p>Redis 官方支持多种开发语言的客户端：https://redis.io/clients</p>
<h2 id="客户端连接-sentinel-工作原理">客户端连接 Sentinel 工作原理<a hidden class="anchor" aria-hidden="true" href="#客户端连接-sentinel-工作原理">#</a></h2>
<ol>
<li>客户端获取 Sentinel 节点集合,选举出一个 Sentinel</li>
</ol>
<p><img loading="lazy" src="/posts.images/image.assets/1671326052932.png" alt="1671326052932"  />
</p>
<ol start="2">
<li>由这个sentinel 通过masterName 获取master节点信息,客户端通过sentinel get-master-addr-by-name master-name这个api来获取对应主节点信息</li>
</ol>
<p><img loading="lazy" src="/posts.images/image.assets/1671326076150.png" alt="1671326076150"  />
</p>
<ol start="3">
<li>客户端发送role指令确认master的信息,验证当前获取的“主节点”是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化</li>
</ol>
<p><img loading="lazy" src="/posts.images/image.assets/1671326092067.png" alt="1671326092067"  />
</p>
<ol start="4">
<li>客户端保持和Sentinel节点集合的联系，即订阅Sentinel节点相关频道，时刻获取关于主节点的相关信息,获取新的master 信息变化,并自动连接新的master</li>
</ol>
<p><img loading="lazy" src="/posts.images/image.assets/1671326121741.png" alt="1671326121741"  />
</p>
<h2 id="java-连接sentinel哨兵">java 连接Sentinel哨兵<a hidden class="anchor" aria-hidden="true" href="#java-连接sentinel哨兵">#</a></h2>
<p>java 客户端连接Redis：https://github.com/xetorthio/jedis/blob/master/pom.xml</p>
<h2 id="python-连接-sentinel-哨兵">python 连接 Sentinel 哨兵<a hidden class="anchor" aria-hidden="true" href="#python-连接-sentinel-哨兵">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>root@centos8 ~<span style="color:#f92672">]</span><span style="color:#75715e">#yum -y install python3 python3-redis</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@centos8 ~<span style="color:#f92672">]</span><span style="color:#75715e">#vim sentinel_test.py</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/python3</span>
</span></span><span style="display:flex;"><span>import redis
</span></span><span style="display:flex;"><span>from redis.sentinel import Sentinel
</span></span><span style="display:flex;"><span><span style="color:#75715e">#连接哨兵服务器(主机名也可以用域名)</span>
</span></span><span style="display:flex;"><span>sentinel <span style="color:#f92672">=</span> Sentinel<span style="color:#f92672">([(</span><span style="color:#e6db74">&#39;192.168.32.135&#39;</span>, 26379<span style="color:#f92672">)</span>,
</span></span><span style="display:flex;"><span>                   <span style="color:#f92672">(</span><span style="color:#e6db74">&#39;192.168.32.133&#39;</span>, 26379<span style="color:#f92672">)</span>,
</span></span><span style="display:flex;"><span>                   <span style="color:#f92672">(</span><span style="color:#e6db74">&#39;192.168.32.132&#39;</span>, 26379<span style="color:#f92672">)]</span>,
</span></span><span style="display:flex;"><span>socket_timeout<span style="color:#f92672">=</span>0.5<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>redis_auth_pass <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;123456&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#mymaster 是配置哨兵模式的redis集群名称，此为默认值,实际名称按照个人部署案例来填写</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取主服务器地址</span>
</span></span><span style="display:flex;"><span>master <span style="color:#f92672">=</span> sentinel.discover_master<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;mymaster&#39;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;master:&#34;</span>,master<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取从服务器地址</span>
</span></span><span style="display:flex;"><span>slave <span style="color:#f92672">=</span> sentinel.discover_slaves<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;mymaster&#39;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>print<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;slave:&#34;</span>,slave<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取主服务器进行写入</span>
</span></span><span style="display:flex;"><span>master <span style="color:#f92672">=</span> sentinel.master_for<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;mymaster&#39;</span>, socket_timeout<span style="color:#f92672">=</span>0.5,
</span></span><span style="display:flex;"><span>password<span style="color:#f92672">=</span>redis_auth_pass, db<span style="color:#f92672">=</span>0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>w_ret <span style="color:#f92672">=</span> master.set<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;name&#39;</span>, <span style="color:#e6db74">&#39;xy&#39;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#输出：True</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取从服务器进行读取（默认是round-roubin）</span>
</span></span><span style="display:flex;"><span>slave <span style="color:#f92672">=</span> sentinel.slave_for<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;mymaster&#39;</span>, socket_timeout<span style="color:#f92672">=</span>0.5,
</span></span><span style="display:flex;"><span>password<span style="color:#f92672">=</span>redis_auth_pass, db<span style="color:#f92672">=</span>0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>r_ret <span style="color:#f92672">=</span> slave.get<span style="color:#f92672">(</span><span style="color:#e6db74">&#39;name&#39;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>print<span style="color:#f92672">(</span>r_ret<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#输出：xy</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chmod +x sentinel_test.py
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>./sentinel_test.py
</span></span><span style="display:flex;"><span>master: <span style="color:#f92672">(</span><span style="color:#e6db74">&#39;192.168.32.135&#39;</span>, 6379<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>slave: <span style="color:#f92672">[(</span><span style="color:#e6db74">&#39;192.168.32.133&#39;</span>, 6379<span style="color:#f92672">)]</span>
</span></span><span style="display:flex;"><span>b<span style="color:#e6db74">&#39;xy&#39;</span>
</span></span></code></pre></div><h1 id="redis-cluster">Redis Cluster<a hidden class="anchor" aria-hidden="true" href="#redis-cluster">#</a></h1>
<p><img loading="lazy" src="/posts.images/image.assets/1671327580442.png" alt="1671327580442"  />
</p>
<h2 id="redis-cluster-介绍">Redis Cluster 介绍<a hidden class="anchor" aria-hidden="true" href="#redis-cluster-介绍">#</a></h2>
<p>使用哨兵sentinel 只能解决Redis高可用问题，实现Redis的自动故障转移,但仍然无法解决Redis Master
单节点的性能瓶颈问题
为了解决单机性能的瓶颈，提高Redis 服务整体性能，可以使用分布式集群的解决方案
<strong>早期 Redis 分布式集群部署方案：</strong></p>
<ul>
<li>客户端分区：由客户端程序自己实现写入分配、高可用管理和故障转移等,对客户端的开发实现较为复杂</li>
<li>代理服务：客户端不直接连接Redis,而先连接到代理服务，由代理服务实现相应读写分配，当前代理服务都是第三方实现.此方案中客户端实现无需特殊开发,实现容易,但是代理服务节点仍存有单点故障和性能瓶颈问题。比如：豌豆荚开发的 codis</li>
</ul>
<p>Redis 3.0 版本之后推出无中心架构的 Redis Cluster ，支持多个master节点并行写入和故障的自动转移动能</p>
<h2 id="redis-cluster-架构">Redis cluster 架构<a hidden class="anchor" aria-hidden="true" href="#redis-cluster-架构">#</a></h2>
<h3 id="redis-cluster-架构-1">Redis cluster 架构<a hidden class="anchor" aria-hidden="true" href="#redis-cluster-架构-1">#</a></h3>
<p><img loading="lazy" src="/posts.images/image.assets/1671328724924.png" alt="1671328724924"  />
</p>
<p>Redis cluster 需要至少 3个master节点才能实现,slave节点数量不限,当然一般每个master都至少对应的有一个slave节点
如果有三个主节点采用哈希槽 hash slot 的方式来分配16384个槽位 slot
此三个节点分别承担的slot 区间可以是如以下方式分配</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>节点M1 0－5460
</span></span><span style="display:flex;"><span>节点M2 5461－10922
</span></span><span style="display:flex;"><span>节点M3 10923－16383
</span></span></code></pre></div><p><img loading="lazy" src="/posts.images/image.assets/1671328782321.png" alt="1671328782321"  />
</p>
<h3 id="redis-cluster的工作原理">Redis cluster的工作原理<a hidden class="anchor" aria-hidden="true" href="#redis-cluster的工作原理">#</a></h3>
<p><img loading="lazy" src="/posts.images/image.assets/1671328827665.png" alt="1671328827665"  />
</p>
<h4 id="数据分区">数据分区<a hidden class="anchor" aria-hidden="true" href="#数据分区">#</a></h4>
<p>如果是单机存储的话，直接将数据存放在单机redis就行了。但是如果是集群存储，就需要考虑到数据分区了。</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671328870673.png" alt="1671328870673"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671328992908.png" alt="1671328992908"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329004830.png" alt="1671329004830"  />
</p>
<h4 id="集群通信">集群通信<a hidden class="anchor" aria-hidden="true" href="#集群通信">#</a></h4>
<p>但是寻找槽的过程并不是一次就命中的，比如上图key将要存放在14396槽中，但是并不是一下就锁定了node3节点，可能先去询问node1，然后才访问node3。
而集群中节点之间的通信，保证了最多两次就能命中对应槽所在的节点。因为在每个节点中，都保存了其他节点的信息，知道哪个槽由哪个节点负责。这样即使第一次访问没有命中槽，但是会通知客户端，该槽在哪个节点，这样访问对应节点就能精准命中。</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329162018.png" alt="1671329162018"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329175313.png" alt="1671329175313"  />
</p>
<h4 id="集群伸缩">集群伸缩<a hidden class="anchor" aria-hidden="true" href="#集群伸缩">#</a></h4>
<p>集群并不是建立之后，节点数就固定不变的，也会有新的节点加入集群或者集群中的节点下线，这就是集群的扩容和缩容。但是由于集群节点和槽息息相关，所以集群的伸缩也对应了槽和数据的迁移</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329671490.png" alt="1671329671490"  />
</p>
<h4 id="集群扩容">集群扩容<a hidden class="anchor" aria-hidden="true" href="#集群扩容">#</a></h4>
<p>当有新的节点准备好加入集群时，这个新的节点还是孤立节点，加入有两种方式。一个是通过集群节点执行命令来和孤立节点握手，另一个则是使用脚本来添加节点。</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329705222.png" alt="1671329705222"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329719113.png" alt="1671329719113"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329733621.png" alt="1671329733621"  />
</p>
<h4 id="集群缩容">集群缩容<a hidden class="anchor" aria-hidden="true" href="#集群缩容">#</a></h4>
<p><img loading="lazy" src="/posts.images/image.assets/1671329778357.png" alt="1671329778357"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329787950.png" alt="1671329787950"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329813270.png" alt="1671329813270"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329824032.png" alt="1671329824032"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329836794.png" alt="1671329836794"  />
</p>
<h4 id="故障转移">故障转移<a hidden class="anchor" aria-hidden="true" href="#故障转移">#</a></h4>
<p><img loading="lazy" src="/posts.images/image.assets/1671329862455.png" alt="1671329862455"  />
</p>
<p><img loading="lazy" src="/posts.images/image.assets/1671329876909.png" alt="1671329876909"  />
</p>
<p>当从节点走马上任变成主节点之后，就要开始进行替换主节点：</p>
<ol>
<li>让该slave节点执行slaveof no one变为master节点</li>
<li>将故障节点负责的槽分配给该节点</li>
<li>向集群中其他节点广播Pong消息，表明已完成故障转移</li>
<li>故障节点重启后，会成为new_master的slave节点</li>
</ol>
<h2 id="实战案例">实战案例<a hidden class="anchor" aria-hidden="true" href="#实战案例">#</a></h2>
<h3 id="基于redis-5-以上版本的-redis-cluster-部署">基于Redis 5 以上版本的 redis cluster 部署<a hidden class="anchor" aria-hidden="true" href="#基于redis-5-以上版本的-redis-cluster-部署">#</a></h3>
<p>官方文档：https://redis.io/topics/cluster-tutorial</p>
<h4 id="创建-redis-cluster集群的环境准备">创建 redis cluster集群的环境准备<a hidden class="anchor" aria-hidden="true" href="#创建-redis-cluster集群的环境准备">#</a></h4>
<p><img loading="lazy" src="/posts.images/image.assets/1671337258210.png" alt="1671337258210"  />
</p>
<ul>
<li>每个Redis 节点采用相同的相同的Redis版本、相同的密码、硬件配置</li>
<li>所有Redis服务器必须没有任何数据</li>
<li>准备六台主机，地址如下：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>192.168.32.132
</span></span><span style="display:flex;"><span>192.168.32.137
</span></span><span style="display:flex;"><span>192.168.32.140
</span></span><span style="display:flex;"><span>192.168.32.129
</span></span><span style="display:flex;"><span>192.168.32.136
</span></span><span style="display:flex;"><span>192.168.32.138
</span></span></code></pre></div><h4 id="启用-redis-cluster-配置">启用 redis cluster 配置<a hidden class="anchor" aria-hidden="true" href="#启用-redis-cluster-配置">#</a></h4>
<p>每个节点安装相同版每个节点修改redis配置，必须开启cluster功能的参数</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>vim /etc/redis.conf
</span></span><span style="display:flex;"><span>bind 0.0.0.0
</span></span><span style="display:flex;"><span>masterauth 123456 #建议配置，否则后期的master和slave主从复制无法成功，还需再配置
</span></span><span style="display:flex;"><span>requirepass 123456
</span></span><span style="display:flex;"><span>cluster-enabled yes #取消此行注释,必须开启集群，开启后 redis 进程会有cluster标识
</span></span><span style="display:flex;"><span>cluster-config-file nodes-6379.conf #取消此行注释,此为集群状态数据文件,记录主从关系
</span></span><span style="display:flex;"><span>及slot范围信息,由redis cluster 集群自动创建和维护
</span></span><span style="display:flex;"><span>cluster-require-full-coverage no #默认值为yes,设为no可以防止一个节点不可用导致整
</span></span><span style="display:flex;"><span>个cluster不可用
</span></span></code></pre></div><p>以下方式二选一</p>
<ul>
<li>执行下面命令,批量修改</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sed -i.bak -e &#39;s/bind 127.0.0.1/bind 0.0.0.0/&#39; -e &#39;/masterauth/a masterauth 123456&#39; -e &#39;/# requirepass/a requirepass 123456&#39; -e &#39;/# cluster-enabled yes/a cluster-enabled yes&#39; -e &#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#39; -e &#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#39; /etc/redis.conf
</span></span></code></pre></div><ul>
<li>如果是编译安装可以执行下面操作</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>sed -i.bak -e &#39;/masterauth/a masterauth 123456&#39; -e &#39;/# cluster-enabled yes/a cluster-enabled yes&#39; -e &#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#39; -e &#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#39; /usr/local/src/redis/etc/redis.conf
</span></span></code></pre></div><p>开机启动redis</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>systemctl enable --now redis
</span></span><span style="display:flex;"><span># 修改完配置文件重启redis
</span></span><span style="display:flex;"><span>systemctl restart redis
</span></span></code></pre></div><p>验证当前Redis服务状态：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#开启了16379的cluster的端口,实际的端口=redis port + 10000
</span></span><span style="display:flex;"><span>[root@centos7 ~]# ss -ntl
</span></span><span style="display:flex;"><span>State      Recv-Q Send-Q                       Local Address:Port                                      Peer Address:Port              
</span></span><span style="display:flex;"><span>LISTEN     0      128                                      *:22                                                   *:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      100                              127.0.0.1:25                                                   *:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      511                                      *:16379                                                *:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      511                                      *:6379                                                 *:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      128                                   [::]:22                                                [::]:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      100                                  [::1]:25                                                [::]:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      511                                  [::1]:16379                                             [::]:*                  
</span></span><span style="display:flex;"><span>LISTEN     0      511                                  [::1]:6379                                              [::]:*                  
</span></span><span style="display:flex;"><span>[root@centos7 ~]# 
</span></span></code></pre></div><h4 id="创建集群">创建集群<a hidden class="anchor" aria-hidden="true" href="#创建集群">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#命令redis-cli的选项 --cluster-replicas 1 表示每个master对应一个slave节点
</span></span><span style="display:flex;"><span># 默认前三个为主节点
</span></span><span style="display:flex;"><span>[root@centos8 etc]# redis-cli -a 123456 --cluster create 192.168.32.132:6379 192.168.32.137:6379 192.168.32.140:6379 192.168.32.129:6379 192.168.32.136:6379 192.168.32.138:6379 --cluster-replicas 1
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...
</span></span><span style="display:flex;"><span>Master[0] -&gt; Slots 0 - 5460
</span></span><span style="display:flex;"><span>Master[1] -&gt; Slots 5461 - 10922
</span></span><span style="display:flex;"><span>Master[2] -&gt; Slots 10923 - 16383
</span></span><span style="display:flex;"><span>Adding replica 192.168.32.136:6379 to 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Adding replica 192.168.32.138:6379 to 192.168.32.137:6379
</span></span><span style="display:flex;"><span>Adding replica 192.168.32.129:6379 to 192.168.32.140:6379
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[0-5460] (5461 slots) master
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[5461-10922] (5462 slots) master
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[10923-16383] (5461 slots) master
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>Can I set the above configuration? (type &#39;yes&#39; to accept): yes
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Nodes configuration updated
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Assign a different config epoch to each node
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster
</span></span><span style="display:flex;"><span>Waiting for the cluster to join
</span></span><span style="display:flex;"><span>.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[0-5460] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[10923-16383] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[5461-10922] (5462 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span></code></pre></div><h4 id="验证集群">验证集群<a hidden class="anchor" aria-hidden="true" href="#验证集群">#</a></h4>
<ul>
<li>查看主从状态</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:6379&gt; info replication
</span></span><span style="display:flex;"><span># Replication
</span></span><span style="display:flex;"><span>role:master
</span></span><span style="display:flex;"><span>connected_slaves:1
</span></span><span style="display:flex;"><span>slave0:ip=192.168.32.136,port=6379,state=online,offset=98,lag=1
</span></span><span style="display:flex;"><span>master_failover_state:no-failover
</span></span><span style="display:flex;"><span>master_replid:b1bd51213722f38a83c8bb525e8a74e62392a161
</span></span><span style="display:flex;"><span>master_replid2:0000000000000000000000000000000000000000
</span></span><span style="display:flex;"><span>master_repl_offset:98
</span></span><span style="display:flex;"><span>second_repl_offset:-1
</span></span><span style="display:flex;"><span>repl_backlog_active:1
</span></span><span style="display:flex;"><span>repl_backlog_size:1048576
</span></span><span style="display:flex;"><span>repl_backlog_first_byte_offset:1
</span></span><span style="display:flex;"><span>repl_backlog_histlen:98
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; 
</span></span></code></pre></div><ul>
<li>
<p>验证集群状态</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>127.0.0.1:6379&gt; CLUSTER INFO
</span></span><span style="display:flex;"><span>cluster_state:ok
</span></span><span style="display:flex;"><span>cluster_slots_assigned:16384
</span></span><span style="display:flex;"><span>cluster_slots_ok:16384
</span></span><span style="display:flex;"><span>cluster_slots_pfail:0
</span></span><span style="display:flex;"><span>cluster_slots_fail:0
</span></span><span style="display:flex;"><span>cluster_known_nodes:6    # 节点数
</span></span><span style="display:flex;"><span>cluster_size:3           # 三个集群
</span></span><span style="display:flex;"><span>cluster_current_epoch:6
</span></span><span style="display:flex;"><span>cluster_my_epoch:1
</span></span><span style="display:flex;"><span>cluster_stats_messages_ping_sent:210
</span></span><span style="display:flex;"><span>cluster_stats_messages_pong_sent:210
</span></span><span style="display:flex;"><span>cluster_stats_messages_sent:420
</span></span><span style="display:flex;"><span>cluster_stats_messages_ping_received:205
</span></span><span style="display:flex;"><span>cluster_stats_messages_pong_received:210
</span></span><span style="display:flex;"><span>cluster_stats_messages_meet_received:5
</span></span><span style="display:flex;"><span>cluster_stats_messages_received:420
</span></span><span style="display:flex;"><span>127.0.0.1:6379&gt; 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#查看任意节点的集群状态
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster info 192.168.32.137:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 5462 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.140:6379 (f49ca2e5...) -&gt; 0 keys | 5461 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 5461 slots | 1 slaves.
</span></span><span style="display:flex;"><span>[OK] 0 keys in 3 masters.
</span></span><span style="display:flex;"><span>0.00 keys per slot on average.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span></code></pre></div><h4 id="查看对应关系">查看对应关系<a hidden class="anchor" aria-hidden="true" href="#查看对应关系">#</a></h4>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 CLUSTER NODES
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379@16379 slave f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 0 1671364792207 3 connected
</span></span><span style="display:flex;"><span>658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379@16379 myself,master - 0 1671364792000 1 connected 0-5460
</span></span><span style="display:flex;"><span>f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379@16379 master - 0 1671364792000 3 connected 10923-16383
</span></span><span style="display:flex;"><span>46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379@16379 master - 0 1671364793216 2 connected 5461-10922
</span></span><span style="display:flex;"><span>f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379@16379 slave 658dd91e4b51bf06b161e6903d4084c77abd195d 0 1671364793000 1 connected
</span></span><span style="display:flex;"><span>eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379@16379 slave 46b54e8298e11e77450e232c9a0ee057b362191a 0 1671364792000 2 connected
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span></code></pre></div><h4 id="测试集群写入数据">测试集群写入数据<a hidden class="anchor" aria-hidden="true" href="#测试集群写入数据">#</a></h4>
<p><img loading="lazy" src="/posts.images/image.assets/1671364901011.png" alt="1671364901011"  />
</p>
<ul>
<li>redis cluster 写入key</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#经过算法计算，当前key的槽位需要写入指定的node
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 set k1 v1
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>(error) MOVED 12706 192.168.32.140:6379  #槽位不在当前node所以无法写入
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#指定槽位对应node可写入
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -h 192.168.32.140 -a 123456 set k1 v1
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>OK
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#对应的slave节点可以KEYS *,但GET k1失败,可以到master上执行GET k1
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 get k1
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>(error) MOVED 12706 192.168.32.140:6379
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 keys &#34;*&#34;
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>1) &#34;k1&#34;
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span></code></pre></div><h1 id="redis-cluster-管理">Redis cluster 管理<a hidden class="anchor" aria-hidden="true" href="#redis-cluster-管理">#</a></h1>
<h2 id="集群扩容-1">集群扩容<a hidden class="anchor" aria-hidden="true" href="#集群扩容-1">#</a></h2>
<p>扩容适用场景：
当前客户量激增，现有的Redis cluster架构已经无法满足越来越高的并发访问请求，为解决此问题,新购置两台服务器，要求将其动态添加到现有集群，但不能影响业务的正常访问。
注意: 生产环境一般建议master节点为奇数个,比如:3,5,7,以防止脑裂现象</p>
<ul>
<li>添加节点准备</li>
</ul>
<p>增加Redis 新节点，需要与之前的Redis node版本和配置一致，然后分别再启动两台Redis node，应为一主一从。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>192.168.32.133 主
</span></span><span style="display:flex;"><span>192.168.32.139  从
</span></span><span style="display:flex;"><span># 修改配置文件,主从节点都修改
</span></span><span style="display:flex;"><span>sed -i.bak -e &#39;/masterauth/a masterauth 123456&#39; -e &#39;/# cluster-enabled yes/a cluster-enabled yes&#39; -e &#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#39; -e &#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#39; /usr/local/src/redis/etc/redis.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl restart redis
</span></span></code></pre></div><ul>
<li>添加新的master节点到集群<br>
使用以下命令添加新节点，要添加的新redis节点IP和端口添加到的已有的集群中任意节点的IP:端口</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>add-node new_host:new_port existing_host:existing_port [--slave --master-id
</span></span><span style="display:flex;"><span>&lt;arg&gt;]
</span></span><span style="display:flex;"><span>#说明：
</span></span><span style="display:flex;"><span>new_host:new_port #指定新添加的主机的IP和端口
</span></span><span style="display:flex;"><span>existing_host:existing_port #指定已有的集群中任意节点的IP和端口
</span></span></code></pre></div><ul>
<li>Redis 3/4 版本的添加命令：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#把新的Redis 节点192.168.32.133添加到当前Redis集群当中。
</span></span><span style="display:flex;"><span>[root@redis-node1 ~]#redis-trib.rb add-node 192.168.32.133:6379 192.168.32.132:6379
</span></span></code></pre></div><ul>
<li>Redis 5 以上版本的添加命令：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>#将一台新的主机加入集群
</span></span><span style="display:flex;"><span>[root@redis-node1 ~]#redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 &lt;当前
</span></span><span style="display:flex;"><span>任意集群节点&gt;:6379
</span></span><span style="display:flex;"><span>[root@centos8 data]# redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Adding node 192.168.32.133:6379 to cluster 192.168.32.132:6379
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[0-5460] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[10923-16383] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[5461-10922] (5462 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Send CLUSTER MEET to node 192.168.32.133:6379 to make it join the cluster.
</span></span><span style="display:flex;"><span>[OK] New node added correctly.
</span></span><span style="display:flex;"><span>[root@centos8 data]# 
</span></span></code></pre></div><ul>
<li>在新的master上重新分配槽位
新的node节点加到集群之后,默认是master节点，但是没有slots，需要重新分配,否则没有槽位将无法访问
注意: 重新分配槽位需要清空数据,所以需要先备份数据,扩展后再恢复数据
Redis 3/4 版本命令:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-node1 ~]# redis-trib.rb check 10.0.0.67:6379 #当前状态
</span></span><span style="display:flex;"><span>[root@redis-node1 ~]# redis-trib.rb reshard &lt;任意节点&gt;:6379 #重新分片
</span></span><span style="display:flex;"><span>[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.67:6379 #如果迁移失败使用此命令修复集群
</span></span></code></pre></div><ul>
<li>Redis 5以上版本命令：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-node1 ~]#redis-cli -a 123456 --cluster reshard &lt;当前任意集群节点&gt;:6379
</span></span><span style="display:flex;"><span>[root@centos8 data]# redis-cli -a 123456 --cluster reshard 192.168.32.133:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.133:6379)
</span></span><span style="display:flex;"><span>M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) master
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[0-5460] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[5461-10922] (5462 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[10923-16383] (5461 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>How many slots do you want to move (from 1 to 16384)? 4096
</span></span><span style="display:flex;"><span># 复制新加入的节点的ID，即192.168.32.133的节点ID
</span></span><span style="display:flex;"><span>What is the receiving node ID? 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>Please enter all the source node IDs.
</span></span><span style="display:flex;"><span>  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.
</span></span><span style="display:flex;"><span>  Type &#39;done&#39; once you entered all the source nodes IDs.
</span></span><span style="display:flex;"><span>Source node #1: all     # 选择all
</span></span><span style="display:flex;"><span>Do you want to proceed with the proposed reshard plan (yes/no)? yes
</span></span></code></pre></div><ul>
<li>为新的master指定新的slave节点</li>
</ul>
<p>当前Redis集群中新的master节点存单点问题,还需要给其添加一个对应slave节点，实现高可用功能
有两种方式：
方法1：在新加节点到集群时，直接将之设置为slave
Redis 3/4 添加命令</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>redis-trib.rb add-node --slave --master-id
</span></span><span style="display:flex;"><span>750cab050bc81f2655ed53900fd43d2e64423333 192.168.32.139:6379 &lt;任意集群节点&gt;:6379
</span></span></code></pre></div><p>Redis 5 以上版本添加命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 &lt;任意集群节点&gt;:6379 --
</span></span><span style="display:flex;"><span>cluster-slave --cluster-master-id d6e2eca6b338b717923f64866bd31d42e52edc98
</span></span></code></pre></div><p>范例：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 查看当前状态
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 0 slaves.
</span></span><span style="display:flex;"><span>192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>[OK] 1 keys in 4 masters.
</span></span><span style="display:flex;"><span>0.00 keys per slot on average.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[1365-5460] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379
</span></span><span style="display:flex;"><span>   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[12288-16383] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[6827-10922] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#直接加为slave节点
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 192.168.32.132:6379 --cluster-slave --cluster-master-id 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># 验证
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>[OK] 1 keys in 4 masters.
</span></span><span style="display:flex;"><span>0.00 keys per slot on average.
</span></span></code></pre></div><h2 id="集群缩容-1">集群缩容<a hidden class="anchor" aria-hidden="true" href="#集群缩容-1">#</a></h2>
<p>缩容适用场景：
随着业务萎缩用户量下降明显,和领导商量决定将现有Redis集群的8台主机中下线两台主机挪做它用,缩容后性能仍能满足当前业务需求
删除节点过程：
扩容时是先添加node到集群，然后再分配槽位，而缩容时的操作相反，是先将被要删除的node上的槽位迁移到集群中的其他node上，然后 才能再将其从集群中删除，如果一个node上的槽位没有被完全迁移空，删除该node时也会提示有数据出错导致无法删除。</p>
<p>迁移要删除的master节点上面的槽位到其它master
注意: 被迁移Redis master源服务器必须保证没有数据，否则迁移报错并会被强制中断。
Redis 3/4 版本命令</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-node1 ~]# redis-trib.rb reshard 10.0.0.8:6379
</span></span><span style="display:flex;"><span>[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.8:6379 #如果迁移失败使用此命令修复集群
</span></span></code></pre></div><p>Redis 5版本以上命令</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 查看当前状态
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>[OK] 1 keys in 4 masters.
</span></span><span style="display:flex;"><span>0.00 keys per slot on average.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[1365-5460] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379
</span></span><span style="display:flex;"><span>   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[12288-16383] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[6827-10922] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>#连接到任意集群节点，#最后1365个slot从192.168.32.133移动到第一个master节点192.168.32.132上
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster reshard 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[1365-5460] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379
</span></span><span style="display:flex;"><span>   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[12288-16383] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[6827-10922] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>How many slots do you want to move (from 1 to 16384)? 1356 #共4096/3分别给其它三个master节点
</span></span><span style="display:flex;"><span>What is the receiving node ID? 658dd91e4b51bf06b161e6903d4084c77abd195d # master id
</span></span><span style="display:flex;"><span>Please enter all the source node IDs.
</span></span><span style="display:flex;"><span>  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.
</span></span><span style="display:flex;"><span>  Type &#39;done&#39; once you entered all the source nodes IDs.
</span></span><span style="display:flex;"><span>Source node #1: 77cfc3429c8b470331520074faea7c3a21f77d1f  # 删除ID，192.168.32.133的ID
</span></span><span style="display:flex;"><span>Source node #2: done
</span></span><span style="display:flex;"><span>Do you want to proceed with the proposed reshard plan (yes/no)? yes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 该命令在执行两次
</span></span></code></pre></div><ul>
<li>从集群中删除服务器</li>
</ul>
<p>上面步骤完成后,槽位已经迁移走，但是节点仍然还属于集群成员，因此还需从集群删除该节点
注意: 删除服务器前,必须清除主机上面的槽位,否则会删除主机失败
Redis 3/4命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@s~]#redis-trib.rb del-node &lt;任意集群节点的IP&gt;:6379
</span></span><span style="display:flex;"><span>dfffc371085859f2858730e1f350e9167e287073
</span></span><span style="display:flex;"><span>#dfffc371085859f2858730e1f350e9167e287073 是删除节点的ID
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Removing node dfffc371085859f2858730e1f350e9167e287073 from cluster
</span></span><span style="display:flex;"><span>192.168.7.102:6379
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; SHUTDOWN the node.
</span></span></code></pre></div><p>Redis 5以上版本命令：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>[root@redis-node1 ~]#redis-cli -a 123456 --cluster del-node &lt;任意集群节点的IP&gt;:6379
</span></span><span style="display:flex;"><span>cb028b83f9dc463d732f6e76ca6bbcd469d948a7
</span></span><span style="display:flex;"><span>#cb028b83f9dc463d732f6e76ca6bbcd469d948a7是删除节点的ID
</span></span></code></pre></div><p>范例</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span># 查看节点信息
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 8164 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 28 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.
</span></span><span style="display:flex;"><span>[OK] 1 keys in 4 masters.
</span></span><span style="display:flex;"><span>0.00 keys per slot on average.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)
</span></span><span style="display:flex;"><span>M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379
</span></span><span style="display:flex;"><span>   slots:[0-6826],[10923-12259] (8164 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379
</span></span><span style="display:flex;"><span>   slots:[12260-12287] (28 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e
</span></span><span style="display:flex;"><span>M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379
</span></span><span style="display:flex;"><span>   slots:[12288-16383] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379
</span></span><span style="display:flex;"><span>   slots:[6827-10922] (4096 slots) master
</span></span><span style="display:flex;"><span>   1 additional replica(s)
</span></span><span style="display:flex;"><span>S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 658dd91e4b51bf06b161e6903d4084c77abd195d
</span></span><span style="display:flex;"><span>S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379
</span></span><span style="display:flex;"><span>   slots: (0 slots) slave
</span></span><span style="display:flex;"><span>   replicates 46b54e8298e11e77450e232c9a0ee057b362191a
</span></span><span style="display:flex;"><span>[OK] All nodes agree about slots configuration.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check for open slots...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Check slots coverage...
</span></span><span style="display:flex;"><span>[OK] All 16384 slots covered.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># 删除192.168.32.133节点
</span></span><span style="display:flex;"><span>[root@centos8 ~]# redis-cli -a 123456 --cluster del-node 192.168.32.132:6379 77cfc3429c8b470331520074faea7c3a21f77d1f
</span></span><span style="display:flex;"><span>Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Removing node 77cfc3429c8b470331520074faea7c3a21f77d1f from cluster 192.168.32.132:6379
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...
</span></span><span style="display:flex;"><span>&gt;&gt;&gt; Sending CLUSTER RESET SOFT to the deleted node.
</span></span><span style="display:flex;"><span>[root@centos8 ~]# 
</span></span></code></pre></div><h1 id="常见面试题">常见面试题<a hidden class="anchor" aria-hidden="true" href="#常见面试题">#</a></h1>
<ul>
<li>Redis 做什么的,即在哪些场景下使用</li>
<li>如果监控 Redis 是否出现故障</li>
<li>Redis客户端timeout报错突然增加，排查思路是怎样的？</li>
<li>请简单描述pipeline功能，为什么pipeline功能会提升redis性能?</li>
<li>本地redis-client访问远程Redis服务出错，说出几种常见的错误?</li>
<li>key-value的大小超大或单key的qps超高，会对Redis本身造成什么样的影响、会对访问Redis的其他客户端造成什么样的影响？</li>
<li>Zabbix 监控 Redis 哪些监控项</li>
<li>RDB和AOF持久化区别</li>
<li>docker拉取一个Redis如何实现数据持久化保存</li>
<li>Redis 支持哪些数据类型</li>
<li>Redis 如何实现消息队列</li>
<li>描述下常见的redis集群架构有哪些，他们之间的优缺点对比</li>
<li>主从复制工作原理</li>
<li>Redis 如何实现高可用</li>
<li>哨兵工作原理</li>
<li>Redis 集群的工作原理</li>
<li>Redis 集群如果避免脑裂</li>
<li>Redis 集群最少几个节点为什么?</li>
<li>Redis的集群槽位多少个</li>
<li>Redis集群中某个节点缺少一个槽位是否能使用</li>
<li>Redis数据写入的时候是怎么在各个节点槽位分配数据的</li>
<li>Redis的数据存储是以什么样的方式存储</li>
<li>Redis集群的各槽位和总槽位之间什么关系</li>
</ul>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="http://gz0854.com/posts/centos%E7%B3%BB%E7%BB%9Fyum%E9%85%8D%E7%BD%AE/">
    <span class="title">« 上一页</span>
    <br>
    <span>Centos系统yum源配置</span>
  </a>
  <a class="next" href="http://gz0854.com/posts/redis%E9%83%A8%E7%BD%B2%E5%92%8C%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/">
    <span class="title">下一页 »</span>
    <br>
    <span>Redis部署和基础使用</span>
  </a>
</nav>

        </footer>
    </div>
</article>
</main>

<footer class="footer">
    <span>
        Copyright
        &copy;
        2022-2023
        <a href="http://gz0854.com/" style="color:#939393;">Hopeful</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;"></a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="" style="float:left;margin: 0px 5px 0px 0px;"/>
            
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Hopeful"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Hopeful"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '📄复制';

        function copyingDone() {
            copybutton.innerText = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerText = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"Hopeful"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
